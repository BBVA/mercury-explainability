{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CounterFactual (Basic) Explainer\n",
    "\n",
    "This Notebooks is a tutorial on how to use the Basic Counter Factual (Panellet) Explainer using the Iris dataset as example.\n",
    "\n",
    "In short, the Panellet Explainer assumes a model $M$ which has been trained with a dataset $D$. Then, it tries to answer a question of the following type:\n",
    "\"I have an instance $x$ which the model is predicting a probability $p$ of belonging to the class $C$. What are the necessary changes in the features of the instance $x$ that will make the model predict a different specified probability $p^{\\prime}$ of belonging to the class $C$ ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mercury.explainability'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[1;32m      5\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatplotlib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minline\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmercury\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplainability\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CounterFactualExplainerBasic\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mercury.explainability'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import ensemble\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from mercury.explainability import CounterFactualExplainerBasic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and model fitting\n",
    "\n",
    "Let's load the [iris dataset](https://en.wikipedia.org/wiki/Iris_flower_data_set) to train a complex Random Forest and check some explanations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "rf = ensemble.RandomForestClassifier(n_estimators=500)\n",
    "rf = rf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a starting point to explain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idx = 2\n",
    "from_ = np.array([5.2, 2.1, 2.2, 2.1])\n",
    "print('Point to explain {}, with probability {} for class {}'.format(\n",
    "    from_, rf.predict_proba(from_.reshape(1, -1))[0, class_idx], iris.target_names[class_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Basic (Panellet) Explainer\n",
    "\n",
    "The first step is create the ```CounterFactualExplainerBasic``` with:\n",
    "\n",
    " - Dataset (in order to infer boundaries for each dimension).\n",
    " - Prediction function of the model we want to explain.\n",
    " - Labels of each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_explainer = CounterFactualExplainerBasic(iris.data, fn=rf.predict_proba, labels=iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we use the ```CounterFactualExplainerBasic``` to obtain a explanation using:\n",
    " - **From** a starting point (the one that we want to explain).\n",
    " - **Threshold** that we would like to reach increasing/decreasing values in each dimensions.\n",
    " - **Class index** of desired probability.\n",
    " - Absolute **Step** in each dimension (feature)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = p_explainer.explain(from_=from_, \n",
    "                                  threshold=.9, \n",
    "                                  class_idx=class_idx, \n",
    "                                  step=np.array([.1] * 4))\n",
    "print('Found point with {} probability @ {}'.format(explanation.p, explanation.to_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what ```CounterFactualExplainerBasic``` has just found (```CounterFactualBasicExplanation``` object):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.show(figsize=(8, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where the firsts two plots show how much each feature should be incremented/decremented to reach provided target (```threshold```) for ```class_idx```.\n",
    "\n",
    "The last one shows the probability of each visited path along its trip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Let's see the visited feature space to obtain the explanation\n",
    "\n",
    "Once again, train a classifier but only with 2 features (sepals), in order to plot the probability space, and get the explanation one more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_idx = 1\n",
    "from_ = np.array([6.2, 4.1])\n",
    "\n",
    "rf = ensemble.RandomForestClassifier(n_estimators=500)\n",
    "rf = rf.fit(iris.data[:, :2], iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_explainer = CounterFactualExplainerBasic(iris.data[:, :2], fn=rf.predict_proba, labels=iris.feature_names[:2])\n",
    "\n",
    "explanation = p_explainer.explain(from_=from_, \n",
    "                                  threshold=.9, \n",
    "                                  class_idx=class_idx, \n",
    "                                  step=np.array([.05, .05]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the probability space for every combination of sepals in order to get its probability for ```class_idx```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_, max_ = np.min(iris.data, axis=0), np.max(iris.data, axis=0)\n",
    "X, Y = np.meshgrid(np.arange(min_[0], max_[0], .025), np.arange(min_[1], max_[1], .025))\n",
    "\n",
    "# Get probabilty of class 1 for each feature point in a vectorized fashion\n",
    "z = rf.predict_proba(np.hstack([X.reshape(-1, 1), Y.reshape(-1, 1)]))[:,1].reshape(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot visited points (white opaque dots) and explored points (small and almost transparent white dots) over the probability space. Visited and explored points can be retrieved from ```CounterFactualBasicExplanation``` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path(exp, boundary=False) -> None:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "    cb = ax.contourf(X, Y, z)\n",
    "    if exp.explored is not None and exp.explored.size > 0:\n",
    "        ax.scatter(exp.explored[:,0], exp.explored[:,1], c='w', s=5, alpha=.6)\n",
    "    cb2 = ax.scatter(exp.path[:,0], exp.path[:,1],\n",
    "                     c=range(exp.path.shape[0]), cmap='jet', s=10, alpha=.8)\n",
    "    if boundary:\n",
    "        bb = explanation.bounds\n",
    "        ax.plot([bb[0,0], bb[0,1], bb[0,1], bb[0,0], bb[0,0]], [bb[1,0], bb[1,0], bb[1,1], bb[1,1], bb[1,0]],\n",
    "                lw=3, c='m')\n",
    "    ax.scatter(exp.from_[0], exp.from_[1], c='b', s=30)\n",
    "    ax.scatter(exp.to_[0], exp.to_[1], c='r', s=30)\n",
    "    pcb2 = plt.colorbar(cb2)\n",
    "    pcb2.ax.set_title('Iteration')\n",
    "    pcb1 = plt.colorbar(cb)\n",
    "    pcb1.ax.set_title('Prob.')\n",
    "    ax.set_xlabel(iris.feature_names[0])\n",
    "    ax.set_ylabel(iris.feature_names[1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "plot_path(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this figure, the background represents the Random Forest output probability for each sepal length and sepal width combination.\n",
    "\n",
    "White dots are explored points of the space and colored dots are visited points by the Panellet Explainer where its color is determined by the iteration number it was visited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Panellet Explanations\n",
    "\n",
    "## Going from higher to lower probability!\n",
    "\n",
    "Previous example started from am low probability point and goes to a high one. But sometimes you start from a high probability point and want to descend to a lower probability point. You do not have to do anything, the Panellet Explainer knows when to go up or down ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = p_explainer.explain(from_=np.array([5.5, 2.9]), threshold=.1, class_idx=1, step=np.array([.05, .05]))\n",
    "\n",
    "plot_path(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do not change specific features\n",
    "\n",
    "Sometimes it is hard to explain a change in dimensions like \"country\". That is why Panellet Explainer introduces the *kernel* trick to avoid changes in chosen dimensions. Just revisit the previous example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = p_explainer.explain(from_=np.array([5.5, 2.9]), threshold=.1, class_idx=1,\n",
    "                        step=np.array([.05, .05]), kernel=np.array([.3, 1]))\n",
    "\n",
    "plot_path(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time *x* dimension is highly penalized so the Panellet Explainer avoided moving along the x axis. But you can specify an intermediate value to kernel positions ir order to implement any kind of trade off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying boundaries in feature space to explore\n",
    "\n",
    "Sometimes is not easy to find target value close to the starting point and going far away is always an option!\n",
    "\n",
    "By default, the Panellet Explainer does not move further away than your training data points (that is why training data is required when instantiating ```CounterFactualBasicExplainter``` object).\n",
    "\n",
    "This is because there are implicit **boundaries** that you can make explicit to avoid the Panellet Explainer moving out of desired area.\n",
    "\n",
    "Here is an example of the Panellet Explainer exploring in a restricted area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = p_explainer.explain(from_=np.array([5.3, 2.7]), threshold=.2, class_idx=1,\n",
    "                        step=np.array([.05, .05]), bounds=np.array([[5.2, 6.7], [2.5, 2.9]]))\n",
    "\n",
    "plot_path(explanation, boundary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation.show(figsize=(8, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But I have a high dimensional space and obtaining explanations may take too long!\n",
    "\n",
    "There are two available strategies to obtain explanations:\n",
    "\n",
    " - **Backtracking with priority queue** (default):\n",
    "   - Path of connected neighbours\n",
    "   - Tries to follow a monotonic increasing/decreasing path (avoid ups & downs, hard to explain)\n",
    "   - Guarantees a border point if target is reached\n",
    "   - May be slow if target is far from starting point\n",
    "   - Step parameter can be increased to speed up the search\n",
    "   \n",
    "   \n",
    " - **Simulated annealing**:\n",
    "   - Heuristic non-neighbours search (exploration & exploitation)\n",
    "   - Does not guarantee a monotonic path, even if it exists\n",
    "   - Does not guarantee a border point even when the target is reached\n",
    "   - Faster than Backtracking approach when target is far from the starting point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = p_explainer.explain(from_=np.array([6.2, 4.1]),\n",
    "                        strategy='backtracking',\n",
    "                        threshold=.9,\n",
    "                        class_idx=1,\n",
    "                        step=np.array([.05, .05]))\n",
    "\n",
    "explanation.show(figsize=(8, 5))\n",
    "plot_path(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation = p_explainer.explain(from_=np.array([6.2, 4.1]),\n",
    "                        strategy='simanneal',\n",
    "                        threshold=.9,\n",
    "                        class_idx=1,\n",
    "                        step=np.array([.8, .8]),\n",
    "                        report=True,\n",
    "                        tmax=150,\n",
    "                        tmin=1e-2,\n",
    "                        steps=1000)\n",
    "\n",
    "explanation.show(figsize=(8, 5))\n",
    "plot_path(explanation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
